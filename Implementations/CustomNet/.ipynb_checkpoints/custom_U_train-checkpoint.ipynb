{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354d6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the transforms to be applied to the data\n",
    "# Here, assume that the images are grayscale and need to be resized to 32x32\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc4a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the custom dataset\n",
    "# Here, assume that the dataset is stored in the following directories:\n",
    "# - train: contains training images\n",
    "# - test: contains testing images\n",
    "train_data = datasets.ImageFolder(root=\"E:/Project_A/project_share/Project_A_image_cross/train/U\", transform=transform)\n",
    "test_data_left = datasets.ImageFolder(root=\"E:/Project_A/project_share/Project_A_image_cross/class/left\", transform=transform)\n",
    "test_data_right = datasets.ImageFolder(root=\"E:/Project_A/project_share/Project_A_image_cross/class/right\", transform=transform)\n",
    "test_data_straight = datasets.ImageFolder(root=\"E:/Project_A/project_share/Project_A_image_cross/class/straight\", transform=transform)\n",
    "test_data_U = datasets.ImageFolder(root=\"E:/Project_A/project_share/Project_A_image_cross/class/U\", transform=transform)\n",
    "\n",
    "train_size = int (0.875*len(train_data))\n",
    "train_dataset = data.Subset(train_data,range(train_size))\n",
    "# Create the data loaders\n",
    "batch_size = 30\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader_left = DataLoader(test_data_left, batch_size=batch_size, shuffle=False)\n",
    "test_loader_right = DataLoader(test_data_right, batch_size=batch_size, shuffle=False)\n",
    "test_loader_straight = DataLoader(test_data_straight, batch_size=batch_size, shuffle=False)\n",
    "test_loader_U = DataLoader(test_data_U, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9629c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out1x1, reduce3x3, out3x3, reduce5x5, out5x5, pool_proj):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        # 1x1 convolution branch\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, out1x1, kernel_size=1)\n",
    "        \n",
    "        # 3x3 convolution branch\n",
    "        self.branch3x3_reduce = nn.Conv2d(in_channels, reduce3x3, kernel_size=1)\n",
    "        self.branch3x3 = nn.Conv2d(reduce3x3, out3x3, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 5x5 convolution branch\n",
    "        self.branch5x5_reduce = nn.Conv2d(in_channels, reduce5x5, kernel_size=1)\n",
    "        self.branch5x5 = nn.Conv2d(reduce5x5, out5x5, kernel_size=5, padding=2)\n",
    "        \n",
    "        # Max pooling branch\n",
    "        self.branch_pool = nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch3x3 = self.branch3x3_reduce(x)\n",
    "        branch3x3 = self.branch3x3(branch3x3)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_reduce(x)\n",
    "        branch5x5 = self.branch5x5(branch5x5)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e198319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class custom_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(custom_net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.inception3a = InceptionModule(16, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.fc1 = nn.Linear(480*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.avgpool2(x)\n",
    "        # Apply Inception module\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# Create the model instance and set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = custom_net().to(device)\n",
    "\n",
    "# Define the loss function, optimizer, and learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855dc01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.510\n",
      "Epoch: 1, Batch: 200, Loss: 1.313\n",
      "Epoch: 2, Batch: 100, Loss: 1.220\n",
      "Epoch: 2, Batch: 200, Loss: 1.154\n",
      "Epoch: 3, Batch: 100, Loss: 1.074\n",
      "Epoch: 3, Batch: 200, Loss: 0.955\n",
      "Epoch: 4, Batch: 100, Loss: 0.859\n",
      "Epoch: 4, Batch: 200, Loss: 0.771\n",
      "Epoch: 5, Batch: 100, Loss: 0.687\n",
      "Epoch: 5, Batch: 200, Loss: 0.661\n",
      "Epoch: 6, Batch: 100, Loss: 0.611\n",
      "Epoch: 6, Batch: 200, Loss: 0.585\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 6\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a3060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model left\n",
    "model.eval()\n",
    "\n",
    "# Create empty lists to store the predicted labels and ground truth labels\n",
    "pred_labels_left = []\n",
    "true_labels_left = []\n",
    "correct_left = 0\n",
    "total_left = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader_left:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_left += labels.size(0)\n",
    "        correct_left += (predicted == labels).sum().item()\n",
    "        pred_labels_left += predicted.tolist()\n",
    "        true_labels_left += labels.tolist()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd309f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96091d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e55a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model right\n",
    "\n",
    "# Create empty lists to store the predicted labels and ground truth labels\n",
    "pred_labels_right = []\n",
    "true_labels_right = []\n",
    "correct_right = 0\n",
    "total_right = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader_right:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_right += labels.size(0)\n",
    "        correct_right += (predicted == labels).sum().item()\n",
    "        pred_labels_right += predicted.tolist()\n",
    "        true_labels_right += labels.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802728a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model straight\n",
    "\n",
    "# Create empty lists to store the predicted labels and ground truth labels\n",
    "pred_labels_straight = []\n",
    "true_labels_straight = []\n",
    "correct_straight = 0\n",
    "total_straight = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader_straight:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_straight += labels.size(0)\n",
    "        correct_straight += (predicted == labels).sum().item()\n",
    "        pred_labels_straight += predicted.tolist()\n",
    "        true_labels_straight += labels.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68635c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model U\n",
    "\n",
    "# Create empty lists to store the predicted labels and ground truth labels\n",
    "pred_labels_U = []\n",
    "true_labels_U = []\n",
    "correct_U = 0\n",
    "total_U = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader_U:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_U += labels.size(0)\n",
    "        correct_U += (predicted == labels).sum().item()\n",
    "        pred_labels_U += predicted.tolist()\n",
    "        true_labels_U += labels.tolist()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5640a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the left test images: 61.85%\n",
      "Accuracy of the model on the right test images: 61.72%\n",
      "Accuracy of the model on the straight test images: 64.47%\n",
      "Accuracy of the model on the U test images: 55.46%\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print('Accuracy of the model on the left test images: {:.2f}%'.format(100 * correct_left / total_left))        \n",
    "print('Accuracy of the model on the right test images: {:.2f}%'.format(100 * correct_right / total_right))        \n",
    "print('Accuracy of the model on the straight test images: {:.2f}%'.format(100 * correct_straight / total_straight))\n",
    "print('Accuracy of the model on the U test images: {:.2f}%'.format(100 * correct_U / total_U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595dfb40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_labels_lelft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# calculate F1 scores\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m F1_left \u001b[38;5;241m=\u001b[39m f1_score(\u001b[43mtrue_labels_lelft\u001b[49m, pred_labels_left, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m F1_right \u001b[38;5;241m=\u001b[39m f1_score(true_labels_right, pred_labels_right, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m F1_straight \u001b[38;5;241m=\u001b[39m f1_score(true_labels_straight, pred_labels_straight, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_labels_lelft' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate F1 scores\n",
    "F1_left = f1_score(true_labels_left, pred_labels_left, average='macro')\n",
    "F1_right = f1_score(true_labels_right, pred_labels_right, average='macro')\n",
    "F1_straight = f1_score(true_labels_straight, pred_labels_straight, average='macro')\n",
    "F1_U = f1_score(true_labels_U, pred_labels_U, average='macro')\n",
    "print(f\"F1_lelft = {F1_left}\")\n",
    "print(f\"F1_right = {F1_right}\")\n",
    "print(f\"F1_straight = {F1_straight}\")\n",
    "print(f\"F1_U = {F1_U}\")\n",
    "\n",
    "# calculate the confusion matrixes using scikit-learn\n",
    "cm_left = confusion_matrix(true_labels_left, pred_labels_left)\n",
    "cm_right = confusion_matrix(true_labels_right, pred_labels_right)\n",
    "cm_straight = confusion_matrix(true_labels_straight, pred_labels_straight)\n",
    "cm_U = confusion_matrix(true_labels_U, pred_labels_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of predictions for each class\n",
    "cm_perc_left = cm_left.astype('float') / cm_left.sum(axis=1)[:, np.newaxis] * 100\n",
    "cm_perc_right = cm_right.astype('float') / cm_right.sum(axis=1)[:, np.newaxis] * 100\n",
    "cm_perc_straight = cm_straight.astype('float') / cm_straight.sum(axis=1)[:, np.newaxis] * 100\n",
    "cm_perc_U = cm_U.astype('float') / cm_U.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Define class labels and tick marks\n",
    "class_names = ['Autoriskshwa', 'Bicycle','Fullsize_car','Midsize_car','Truck']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm_perc_left, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix left')\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels to the plot\n",
    "thresh = cm_perc_left.max() / 2.\n",
    "for i, j in np.ndindex(cm_perc_left.shape):\n",
    "    plt.text(j, i, format(cm_perc_left[i, j], '.2f') + '%',\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"black\" )\n",
    "\n",
    "# Add axis labels\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c15ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.imshow(cm_perc_right, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix right')\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels to the plot\n",
    "thresh = cm_perc_right.max() / 2.\n",
    "for i, j in np.ndindex(cm_perc_right.shape):\n",
    "    plt.text(j, i, format(cm_perc_right[i, j], '.2f') + '%',\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"black\" )\n",
    "\n",
    "# Add axis labels\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13563511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.imshow(cm_perc_straight, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix straight')\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels to the plot\n",
    "thresh = cm_perc_straight.max() / 2.\n",
    "for i, j in np.ndindex(cm_perc_straight.shape):\n",
    "    plt.text(j, i, format(cm_perc_straight[i, j], '.2f') + '%',\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"black\" )\n",
    "\n",
    "# Add axis labels\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b95fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.imshow(cm_perc_U, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix U')\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels to the plot\n",
    "thresh = cm_perc_U.max() / 2.\n",
    "for i, j in np.ndindex(cm_perc_U.shape):\n",
    "    plt.text(j, i, format(cm_perc_U[i, j], '.2f') + '%',\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"black\" )\n",
    "\n",
    "# Add axis labels\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
